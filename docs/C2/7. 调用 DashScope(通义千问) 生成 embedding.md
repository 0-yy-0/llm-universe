# 七、调用 DashScope(通义千问) 生成 embedding

## 1. 通义千问

通义千问是阿里云自主研发的超大规模语言模型，能够在用户自然语言输入的基础上，通过自然语言理解和语义分析，在不同领域、任务内为用户提供服务和帮助。模型目前具备的能力包括但不限于：

- 创作文字，如写故事、写公文、写邮件、写剧本、写诗歌等
- 编写代码
- 提供各类语言的翻译服务，如英语、日语、法语、西班牙语等
- 进行文本润色和文本摘要等工作
- 扮演角色进行对话
- 制作图表


在 11 月 30 日，阿里云开源通义千问 720 亿参数模型 Qwen-72B。当前[开源模型](https://github.com/QwenLM/Qwen/blob/main/README_CN.md)的参数规模为 18 亿（1.8B）、70 亿（7B）、140 亿（14B）和 720 亿（72B）。


从[性能数据](https://github.com/QwenLM/Qwen)来看，Qwen-72B 没有辜负大家的期盼。在 MMLU、AGIEval 等 10 个权威基准测评中，Qwen-72B 都拿到了开源模型的最优成绩，成为性能最强的开源模型，甚至超越了开源标杆 Llama 2-70B 和大部分商用闭源模型（部分成绩超越 GPT-3.5 和 GPT-4）。

要知道，在此之前，中国大模型市场还没有出现足以对抗 Llama 2-70B 的优质开源大模型，Qwen-72B 填补了这一空白。之后，国内大中型企业可基于它的强大推理能力开发商业应用，高校、科研院所可基于它开展 AI for Science 等科研工作。


在本章节中，我们同样将讲述两种通过 Python 代码调用通义千问大模型的方法：直接调用通义千问原生接口；使用 LangChain 调用通义千问接口。

## 2. 获取通义千问调用秘钥

同样，要调用通义千问 API，需要先获取通义千问调用秘钥，在代码中需要配置自己的秘钥才能实现对模型的调用。

2.1 [开通DashScope灵积模型服务](https://dashscope.console.aliyun.com/overview?spm=a2c4g.11186623.0.0.482d14e6eITHD5)


DashScope 类似于百度的千帆平台，该服务提供不同模型API接口，方便模型丰富能力的被集成。服务开通后，您将获得每个模型的一定免费额度。

![](../figures/通义千问控制台2.png)

接下来我们可以按照官方模型 API 调用的步骤进行调用。

![](../figures/通义千问控制台3.png)

我们可以在[模型广场](https://dashscope.console.aliyun.com/model)中选择自己需要的模型。
![](../figures/通义千问模型广场.png)

我们可以通过官方的[计费管理](https://dashscope.console.aliyun.com/billing)，查看哪些模型是免费的，哪些是付费的。免费额度是多少

![](../figures/通义千问控制台6.png)

![](../figures/通义千问控制台7.png)

接下来我们可以开始获取我们的 API-KEY。

![](../figures/通义千问控制台4.png)

![](../figures/通义千问控制台5.png)

2.2 安装 DashScope SDK


dashscope 包很好的封装了同 dashscope 平台交互的能力，我们可以很方便地通过 dashscope 获取对应的模型能力。

!pip install dashscope

## 3. 通过 dashscope 请求大模型

跟之前的模型相似，我们为 dashscope 配置申请好的 API-KEY 后就可以 进行模型请求了。


```python
# export DASHSCOPE_API_KEY="YOUR_DASHSCOPE_API_KEY"
import dashscope
dashscope.api_key="sk-b99567e8225a4c09b3e08148eaf98bbe"
```


```python
def get_completion_dashscope(prompt : str, model : str, temperature : float,  max_tokens:int=256):
    # 封装 dashscope 原生接口

    # 具体调用
    messages = [{"role": "user", "content": prompt}]
    response = dashscope.Generation.call(
        model= model,
        messages=messages,
        temperature=temperature, # 模型输出的温度系数，控制输出的随机程度
        max_tokens = max_tokens, # 回复最大长度,
        result_format='message'
    )    # 调用 dashscope 的 ChatCompletion 接口
    return response.output.choices[0].message["content"]

```


```python
get_completion_dashscope("你好", 'qwen-turbo', 0.1 )
```




    '你好！有什么我能帮助你的吗？'



## 4. 调用通义千问原生接口


```python
resp = dashscope.TextEmbedding.call(
model=dashscope.TextEmbedding.Models.text_embedding_v1,
input='你好')
```


```python
emb_len = len(resp.output["embeddings"][0]["embedding"])
```


```python
print(f"生成的 embedding 长度为: {emb_len}")

```

    生成的 embedding 长度为: 1536


## 5. 使用 LangChain 调用通义千问

我们同样可以通过 LangChain 框架来调用通义千问大模型 embedding，以将其接入到我们的应用框架中。

原生的 LangChain 是已经支持通义千问 embedding 的调用。

1. 首先导入包并配置环境变量


```python
from langchain.embeddings.dashscope import DashScopeEmbeddings
```


```python
import os
os.environ["DASHSCOPE_API_KEY"] = dashscope.api_key
```

定义需要获取 embedding 的 query


```python
text1 = "机器学习"
text2 = "深度学习"
text3 = "深度强化学习"
```

指定对应的模型名字并请求 api 获取 embedding。
我们可以通过`embed_query`获得单个文本的 embedding。


```python
embeddings_v1 = DashScopeEmbeddings(
    model="text-embedding-v1",
)
query_emb1_v1 = embeddings_v1.embed_query(text1)
query_emb2_v1 = embeddings_v1.embed_query(text2)
query_emb3_v1 = embeddings_v1.embed_query(text3)
```

同样我们可以用 `embed_documents` 获得文本列表的 embedding 


```python
doc_list = [text1, text2, text3]
doc_embeds = embeddings_v1.embed_documents(doc_list)
```

余弦相似度通常可以用来评估向量模型的效果，对于两个向量，越相似，其余弦相似度应该越高，越不相似，余弦相似度应该越低。


```python
import numpy as np
def cos_sim(vec1, vec2):
    """
    计算两个向量的余弦相似度
    """
    cos_sim = vec1.dot(vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    return cos_sim
```

调用大模型 api 返回的通常是 list，我们需要将其转成向量的形式，以方便计算。


```python
query_emb1_v1 = np.array(query_emb1_v1)
query_emb2_v1 = np.array(query_emb2_v1)
query_emb3_v1 = np.array(query_emb3_v1)

print(f"{text1} 和 {text2} 的 余弦相似度为 {cos_sim(query_emb1_v1, query_emb2_v1)}")
print(f"{text1} 和 {text3} 的 余弦相似度为 {cos_sim(query_emb1_v1, query_emb3_v1)}")
print(f"{text2} 和 {text3} 的 余弦相似度为 {cos_sim(query_emb2_v1, query_emb3_v1)}")
```

    机器学习 和 深度学习 的 余弦相似度为 0.7282370170377971
    机器学习 和 深度强化学习 的 余弦相似度为 0.5928163953158717
    深度学习 和 深度强化学习 的 余弦相似度为 0.84679114501826


通义千问提供了两种 embedding 模型，"text-embedding-v1" 和 "text-embedding-v2", 我们可以对比其余弦相似度来比较两个模型的效果。


```python
embeddings_v2 = DashScopeEmbeddings(
    model="text-embedding-v2",
)
query_emb1_v2 = embeddings_v2.embed_query(text1)
query_emb2_v2 = embeddings_v2.embed_query(text2)
query_emb3_v2 = embeddings_v2.embed_query(text3)

query_emb1_v2 = np.array(query_emb1_v2)
query_emb2_v2 = np.array(query_emb2_v2)
query_emb3_v2 = np.array(query_emb3_v2)

print(f"{text1} 和 {text2} 的 余弦相似度为 {cos_sim(query_emb1_v2, query_emb2_v2)}")
print(f"{text1} 和 {text3} 的 余弦相似度为 {cos_sim(query_emb1_v2, query_emb3_v2)}")
print(f"{text2} 和 {text3} 的 余弦相似度为 {cos_sim(query_emb2_v2, query_emb3_v2)}")
```

    机器学习 和 深度学习 的 余弦相似度为 0.7011426408395373
    机器学习 和 深度强化学习 的 余弦相似度为 0.5483021420739166
    深度学习 和 深度强化学习 的 余弦相似度为 0.8325364132130924

